{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==2.1.0\nimport tensorflow as tf\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:52:54.981956Z","iopub.execute_input":"2022-01-27T15:52:54.982464Z","iopub.status.idle":"2022-01-27T15:53:26.045550Z","shell.execute_reply.started":"2022-01-27T15:52:54.982407Z","shell.execute_reply":"2022-01-27T15:53:26.044021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.test.is_gpu_available()","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:53:26.047304Z","iopub.execute_input":"2022-01-27T15:53:26.047565Z","iopub.status.idle":"2022-01-27T15:53:27.926586Z","shell.execute_reply.started":"2022-01-27T15:53:26.047539Z","shell.execute_reply":"2022-01-27T15:53:27.925427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: |https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-01-27T15:53:27.928170Z","iopub.execute_input":"2022-01-27T15:53:27.928729Z","iopub.status.idle":"2022-01-27T15:53:27.988984Z","shell.execute_reply.started":"2022-01-27T15:53:27.928688Z","shell.execute_reply":"2022-01-27T15:53:27.988275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# Corresponding changes are to be made here\n# if the feature description in tf2_preprocessing.py\n# is changed\nfeature_description = {\n    'segment': tf.io.FixedLenFeature([], tf.string),\n    'file': tf.io.FixedLenFeature([], tf.string),\n    'num': tf.io.FixedLenFeature([], tf.int64)\n}\n\n\ndef build_dataset(dir_path, batch_size=16, file_buffer=500*1024*1024,\n                  shuffle_buffer=1024, label=1):\n    '''Return a tf.data.Dataset based on all TFRecords in dir_path\n    Args:\n    dir_path: path to directory containing the TFRecords\n    batch_size: size of batch ie #training examples per element of the dataset\n    file_buffer: for TFRecords, size in bytes\n    shuffle_buffer: #examples to buffer while shuffling\n    label: target label for the example\n    '''\n    # glob pattern for files\n    file_pattern = os.path.join(dir_path, '*.tfrecord')\n    # stores shuffled filenames\n    file_ds = tf.data.Dataset.list_files(file_pattern)\n    # read from multiple files in parallel\n    ds = tf.data.TFRecordDataset(file_ds,\n                                 num_parallel_reads=tf.data.experimental.AUTOTUNE,\n                                 buffer_size=file_buffer)\n    # randomly draw examples from the shuffle buffer\n    ds = ds.shuffle(buffer_size=shuffle_buffer,\n                    reshuffle_each_iteration=True)\n    # batch the examples\n    # dropping remainder for now, trouble when parsing - adding labels\n    ds = ds.batch(batch_size, drop_remainder=True)\n    # parse the records into the correct types\n    ds = ds.map(lambda x: _my_parser(x, label, batch_size),\n                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n    return ds\n\n\ndef _my_parser(examples, label, batch_size):\n    '''Parses a batch of serialised tf.train.Example(s)\n    Args:\n    example: a batch serialised tf.train.Example(s)\n    Returns:\n    a tuple (segment, label)\n    where segment is a tensor of shape (#in_batch, #frames, h, w, #channels)\n    '''\n    # ex will be a tensor of serialised tensors\n    ex = tf.io.parse_example(examples, features=feature_description)\n    ex['segment'] = tf.map_fn(lambda x: _parse_segment(x),\n                              ex['segment'], dtype=tf.uint8)\n    # ignoring filename and segment num for now\n    # returns a tuple (tensor1, tensor2)\n    # tensor1 is a batch of segments, tensor2 is the corresponding labels\n    return (ex['segment'], tf.fill((batch_size, 1), label))\n\n\ndef _parse_segment(segment):\n    '''Parses a segment and returns it as a tensor\n    A segment is a serialised tensor of a number of encoded jpegs\n    '''\n    # now a tensor of encoded jpegs\n    parsed = tf.io.parse_tensor(segment, out_type=tf.string)\n    # now a tensor of shape (#frames, h, w, #channels)\n    parsed = tf.map_fn(lambda y: tf.io.decode_jpeg(y), parsed, dtype=tf.uint8)\n    return parsed\n\n\ndef display_segment(segment, batch_size):\n    fig = plt.figure(figsize=(16, 16))\n    columns = int(math.sqrt(batch_size))\n    rows = math.ceil(batch_size / float(columns))\n    for i in range(1, columns*rows + 1):\n        img = segment[i-1]\n        fig.add_subplot(rows, columns, i)\n        plt.imshow(img)\n    plt.show()\n\ntest_feature_description = {\n    'segment': tf.io.FixedLenFeature([], tf.string),\n    'file': tf.io.FixedLenFeature([], tf.string),\n    'num': tf.io.FixedLenFeature([], tf.int64),\n    'label': tf.io.FixedLenFeature([], tf.int64)\n}\n\n\ndef build_test_dataset(dir_path, batch_size=16, file_buffer=500*1024*1024):\n    '''Return a tf.data.Dataset based on all TFRecords in dir_path\n    Args:\n    dir_path: path to directory containing the TFRecords\n    batch_size: size of batch ie #training examples per element of the dataset\n    file_buffer: for TFRecords, size in bytes\n    label: target label for the example\n    '''\n    # glob pattern for files\n    file_pattern = os.path.join(dir_path, '*.tfrecord')\n    # stores shuffled filenames\n    file_ds = tf.data.Dataset.list_files(file_pattern)\n    # read from multiple files in parallel\n    ds = tf.data.TFRecordDataset(file_ds,\n                                 num_parallel_reads=tf.data.experimental.AUTOTUNE,\n                                 buffer_size=file_buffer)\n    # batch the examples\n    # dropping remainder for now, trouble when parsing - adding labels\n    ds = ds.batch(batch_size, drop_remainder=True)\n    # parse the records into the correct types\n    ds = ds.map(lambda x: _my_test_parser(x, batch_size=batch_size),\n                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n    return ds\n\ndef _my_test_parser(examples, batch_size):\n    '''Parses a batch of serialised tf.train.Example(s)\n    Args:\n    example: a batch serialised tf.train.Example(s)\n    Returns:\n    a tuple (segment, label)\n    where segment is a tensor of shape (#in_batch, #frames, h, w, #channels)\n    '''\n    # ex will be a tensor of serialised tensors\n    ex = tf.io.parse_example(examples, features=test_feature_description)\n    ex['segment'] = tf.map_fn(lambda x: _parse_segment(x),\n                              ex['segment'], dtype=tf.uint8)\n    # ignoring filename and segment num for now\n    # returns a tuple (tensor1, tensor2)\n    # tensor1 is a batch of segments, tensor2 is the corresponding labels\n    return (ex['segment'], ex['label'])","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:53:27.996685Z","iopub.execute_input":"2022-01-27T15:53:27.997063Z","iopub.status.idle":"2022-01-27T15:53:28.030424Z","shell.execute_reply.started":"2022-01-27T15:53:27.997025Z","shell.execute_reply":"2022-01-27T15:53:28.029742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.layers import (Input, Activation,\n                                     BatchNormalization, Conv3D,\n                                     LeakyReLU, Conv3DTranspose)\nfrom tensorflow.keras.layers import MaxPool3D\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.backend as K\n\n\ndef AutoEncoderModel():\n    # encoder\n    X_input = Input((16, 128, 128, 3))\n\n    X = Conv3D(32, 3, padding='same')(X_input)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    X = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(X)\n    # current shape is 8x64x64x32\n    X = Conv3D(48, 3, padding='same')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    X = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(X)\n    # current shape is 4x32x32x48\n    X = Conv3D(64, 3, padding='same')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    X = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(X)\n    # current shape is 2x16x16x64\n    X = Conv3D(64, 3, padding='same')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    X = MaxPool3D(pool_size=(2, 2, 2), strides=(1, 1, 1), padding='same')(X)\n    # current shape is 2x16x16x64\n    # decoder\n\n    X = Conv3DTranspose(48, 2, strides=(2, 2, 2), padding='valid')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    # current shape is 4x32x32x48\n    X = Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='valid')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    # current shape is 8x64x64x32\n    X = Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='valid')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    # current shape is 16x128x128x32\n    X = Conv3D(3, 3, strides=(1, 1, 1), padding='same')(X)\n    X = Activation('sigmoid')(X)\n    # current shape is 16x128x128x3\n\n    model = Model(inputs=X_input, outputs=X, name='AutoEncoderModel')\n    return model\n\n\ndef custom_loss(new, original):\n    reconstruction_error = K.mean(K.square(new-original))\n    return reconstruction_error\n\nautoEncoderModel = AutoEncoderModel()\nopt = keras.optimizers.Adam(lr=0.001)\nautoEncoderModel.compile(\n    loss=custom_loss, optimizer=opt, metrics=['accuracy'])\nprint(autoEncoderModel.summary())","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:53:28.033776Z","iopub.execute_input":"2022-01-27T15:53:28.034101Z","iopub.status.idle":"2022-01-27T15:53:28.737946Z","shell.execute_reply.started":"2022-01-27T15:53:28.034053Z","shell.execute_reply":"2022-01-27T15:53:28.736431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.layers import Flatten,Dense\nfrom tensorflow.keras import Sequential\ndef create_discriminator_model():\n\n    X_input = Input((16, 128, 128, 3))\n\n    # not sure about the axis in batch norm\n    # do we also add dropout after batchnorm/pooling?\n\n    # Convolutional Layers\n    # changed the no of filters\n    model= Sequential()\n    model.add(Conv3D(filters=48, kernel_size=(2, 2, 2), padding=\"same\",input_shape=(16, 128, 128, 3)))\n    model.add(BatchNormalization())\n#     model.add(Activation('relu'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    model.add(Conv3D(filters=64, kernel_size=(2, 2, 2), padding=\"same\"))\n    model.add(BatchNormalization())\n#     model.add(Activation('relu'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    model.add(Conv3D(filters=128, kernel_size=(2, 2, 2), padding=\"same\"))\n    model.add(BatchNormalization())\n#     model.add(Activation('relu'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    model.add(Conv3D(filters=128, kernel_size=(2, 2, 2), padding=\"same\"))\n    model.add(BatchNormalization())\n#     model.add(Activation('relu'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    # to add the 5th layer change the cap to 32 frames\n\n    # X=Conv3D(filters=256,kernel_size=(2,2,2),padding=\"same\")(X)\n    # X=BatchNormalization()(X)\n    # X=Activation('relu')(X)\n    # X=MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(X)\n\n    # Fully connected layers\n\n    model.add(Flatten())\n\n    model.add(Dense(256, activation='relu'))\n    # add batch norm to dense layer\n    model.add(BatchNormalization())\n    # activation done with loss fn\n    # for numerical stability\n    model.add(Dense(1, activation='sigmoid'))\n\n    return model\n\n\ndiscriminator = create_discriminator_model()\nopt = keras.optimizers.Adam(lr=0.001)\nloss = BinaryCrossentropy()\ndiscriminator.compile(loss=loss,\n                      optimizer=opt,\n                      metrics=['accuracy'])\nprint(discriminator.summary())\n","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:53:28.739454Z","iopub.execute_input":"2022-01-27T15:53:28.739805Z","iopub.status.idle":"2022-01-27T15:53:29.146996Z","shell.execute_reply.started":"2022-01-27T15:53:28.739770Z","shell.execute_reply":"2022-01-27T15:53:29.146247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom cv2 import VideoWriter, VideoWriter_fourcc\nclass GAN():\n    def __init__(self, mini_batch_size):\n        self.image_shape=(16,128,128,3)\n        learning_rate=0.003\n        opt=keras.optimizers.Adam(lr=learning_rate)\n        opt1=keras.optimizers.Adam(lr=learning_rate)\n        opt_slow=keras.optimizers.Adam(lr=0.01)\n        #Build and compile the discriminator\n        self.discriminator=create_discriminator_model()\n        self.discriminator.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy',tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n        #Build and compile the generator\n        self.generator=AutoEncoderModel()\n        self.generator.compile(loss='mse',optimizer=opt_slow)\n\n        #the generator takes a video as input and generates a modified video\n        z = Input(shape=(self.image_shape))\n        img = self.generator(z)\n        self.discriminator.trainable = False\n        validity = self.discriminator(img)\n        self.combined = Model(z, validity)\n        self.combined.compile(loss='binary_crossentropy', optimizer=opt1,metrics=['accuracy',tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n        self.dir_path = '/kaggle/input/ucf-crime-training-subset/tfrecords2/'\n        self.ds = build_dataset(self.dir_path, batch_size=mini_batch_size,file_buffer=512*1024)\n    \n    def train(self,epochs,mini_batch_size):\n        #this function will need to be added later\n        tf.summary.trace_off()\n        for epoch in range(epochs):\n            d_loss_sum=tf.zeros(6)\n            reconstruct_error_sum=0\n            g_loss_sum=tf.zeros(6)\n            no_of_minibatches=0\n            for minibatch,labels in self.ds:\n                # ---------------------\n                #  Train Discriminator\n                # ---------------------\n                #normalize inputs\n                no_of_minibatches+=1\n                minibatch=tf.cast(tf.math.divide(minibatch,255), tf.float32)\n                gen_vids=self.generator.predict(minibatch)\n                #might have to combine these to improve batch norm\n                self.discriminator.trainable = True\n                d_loss_real=self.discriminator.train_on_batch(minibatch,tf.ones((mini_batch_size,1)))\n                d_loss_fake=self.discriminator.train_on_batch(gen_vids,tf.zeros((mini_batch_size,1)))\n                d_loss=0.5*tf.math.add(d_loss_real,d_loss_fake)\n                # ---------------------\n                #  Train Generator\n                # ---------------------\n                # The generator wants the discriminator to label the generated samples as valid (ones)\n                self.discriminator.trainable = False\n                valid_y = tf.ones((mini_batch_size,1))\n                # Train the generator\n                g_loss = self.combined.train_on_batch(minibatch,valid_y)\n                reconstruct_error=self.generator.train_on_batch(minibatch,minibatch)\n                d_loss_sum+=d_loss\n                g_loss_sum+=g_loss\n                reconstruct_error_sum+=reconstruct_error\n            print(no_of_minibatches)\n            self.combined.save_weights('/kaggle/working/weights_epoch%d.h5' %(epoch+21))\n            g_loss=g_loss_sum/no_of_minibatches\n            d_loss=d_loss_sum/no_of_minibatches\n            reconstruct_error=reconstruct_error_sum/no_of_minibatches\n            # Plot the progress\n            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f, accuracy %.2f%% from which %f is combined loss and %f is reconstruction loss]\" % (epoch+21, d_loss[0], 100*d_loss[1], g_loss[0]+reconstruct_error,g_loss[1]*100,g_loss[0],reconstruct_error))\n        tf.summary.trace_on()\n    \n    def test(self,dev_set_path,mini_batch_size):\n        dev_set=build_test_dataset(dev_set_path,batch_size=mini_batch_size,file_buffer=500*1024)\n        no_of_minibatches=0\n        ans_c=tf.zeros(6)\n        ans_d=tf.zeros(6)\n        for minibatch,labels in dev_set:\n            no_of_minibatches+=1\n            ans_c=self.combined.test_on_batch(minibatch,(labels==0),reset_metrics=(no_of_minibatches==1))\n            ans_d=self.combined.test_on_batch(minibatch,(labels==0),reset_metrics=(no_of_minibatches==1))\n        print(\"Tested Normal vs Anomaly on %d minibatches\" %(no_of_minibatches))\n        print(\"For Combined Model: loss %f accuracy %.2f%% , TP- %d, FP- %d, TN- %d, FN - %d\" %(ans_c[0],ans_c[1]*100,ans_c[2],ans_c[3],ans_c[4],ans_c[5]))\n        print(\"For Discriminator: loss %f accuracy %.2f%% , TP- %d, FP- %d, TN- %d, FN - %d\" %(ans_d[0],ans_d[1]*100,ans_d[2],ans_d[3],ans_d[4],ans_d[5]))\n    \n    def test_real_vs_fake(self,dev_set_path,mini_batch_size):\n        dev_set=build_dataset(dev_set_path,batch_size=mini_batch_size,file_buffer=500*1024)\n        ans_c=tf.zeros(6)\n        ans_d=tf.zeros(6)\n        no_of_minibatches=0\n        for minibatch,labels in dev_set:\n            no_of_minibatches+=1\n            ans_c=self.combined.test_on_batch(minibatch,labels,reset_metrics=(no_of_minibatches==1))\n            ans_d=self.discriminator.test_on_batch(minibatch,labels,reset_metrics=(no_of_minibatches==1))\n            fake_vals=np.random.random((mini_batch_size,16,128,128,3))\n            ans_c=self.combined.test_on_batch(fake_vals,tf.zeros((mini_batch_size,1)),reset_metrics=False)\n            ans_d=self.discriminator.test_on_batch(fake_vals,tf.zeros((mini_batch_size,1)),reset_metrics=False)\n        print(\"Tested Real Vs Fake on %d minibatches\" %(no_of_minibatches))\n        print(\"For Combined Model: loss %f accuracy %.2f%% , TP- %d, FP- %d, TN- %d, FN - %d\" %(ans_c[0],ans_c[1]*100,ans_c[2],ans_c[3],ans_c[4],ans_c[5]))\n        print(\"For Discriminator: loss %f accuracy %.2f%% , TP- %d, FP- %d, TN- %d, FN - %d\" %(ans_d[0],ans_d[1]*100,ans_d[2],ans_d[3],ans_d[4],ans_d[5]))\n        \n        \n    def visualise_autoencoder_outputs(self,no_of_minibatches):\n        fourcc = VideoWriter_fourcc(*'MP42') #some code required for VideoWriter\n        video = VideoWriter('/kaggle/working/reconstructed_video.avi', fourcc, float(24), (128, 128)) #creates video to store 1st segment\n        for i in range(no_of_minibatches):\n            inp=np.load(\"../input/normal-videos-for-checking-autoencoder/minibatches/minibatch%d.npz\" % (i))\n            inp=inp['arr_0']\n            inp=tf.cast(tf.math.divide(inp,255), tf.float32)\n            gen_vids=self.generator.predict(inp)\n            gen_vids*=255\n            for j in range(16):\n                for k in range(16):\n                    frame = np.uint8(gen_vids[j][k])\n                    video.write(frame)\n        print(\"Done! Reconstructed Video is now available\")\n                    \n                    \n            \n        \n        \n        \n    \n        \n# BATCH SIZE WAS MOVED TO INIT, PROBABLY NOT THE BEST WAY TO DO IT\ngan = GAN(16)\ngan.combined.load_weights('../input/saved-models/weights_leaky_relu_epoch30.h5')\nprint(gan.combined.summary())\nprint(gan.discriminator.summary())\nprint(gan.generator.summary())","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:53:29.150992Z","iopub.execute_input":"2022-01-27T15:53:29.151240Z","iopub.status.idle":"2022-01-27T15:53:31.395292Z","shell.execute_reply.started":"2022-01-27T15:53:29.151214Z","shell.execute_reply":"2022-01-27T15:53:31.393674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gan.train(10,16)\ngan.test('../input/anomaly-detection-dev-set/ValidSet',16)\ngan.test_real_vs_fake('../input/anomaly-detection-dev-set/ValidSet',16)\ngan.visualise_autoencoder_outputs(8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}